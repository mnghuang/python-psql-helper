'''
A Psql helper module
~~~~~~~~~~~~~~~~~~~~

Author: Ming Huang
Last Edit Date: 09/14/2015

The module included is intended to make it easier to quickly to load csv data 
into Psql and prevent having to write multiple create and insert queries, and 
is a byproduct of the Galvanize Data Science Capstone project.

This is only a first iteration, please feel free to contact me if you see 
something wrong.  Error handling has not been included yet.
'''

import psycopg2
import os
import re


class PsqlConnection(object):
    '''
    Provides an interface for quick table creation and data insertion into Psql
    databases using Python.  This module is created with the intention for 
    quick data and automated Psql data storage without having to experiment 
    with writing create and insert queries against uncertain data types.  

    While this is not conventional database practice, and does make it easier 
    to quickly transition into EDA using SQL for Data Science projects.

    Usage:

    psql = PsqlConnection(db='dbname', user='username')
    psql.create_table(headers, 'tablename')
    psql.insert_csv('tablename', 'csvpath')
    psql.load_csvs_in_directory('folderpath')
    '''

    def __init__(self, db, user, host='localhost'):
        '''
        INPUT:
            db -> string; name of database
            user -> string; name of database user
            host -> string; database ip address

        Initiates PsqlConnection class.  This class enables automated table 
        generations and data insertions on an existing psql database.
        '''
        self.conn = psycopg2.connect(dbname=db, user=user, host=host)
        self.cur = self.conn.cursor()
        self.db = db
        self.user = user
        self.host = host
        print 'Connection Open'

    def create_table(self, headers, table_name):
        '''
        INPUT:
            headers -> list; list of names of columns for new table
            table_name -> string; name of table to be created

        Creates a new table in existing database using the given list of 
        headers.  The query gets automatically generated by setting all columns
         to varchar.
        '''
        create_query = 'CREATE TABLE {0} ({1});'
        cols = self._varchar_columns(headers)
        self.cur.execute(create_query.format(table_name, cols))
        self.conn.commit()
        print 'Table {0} created in {1}'.format(table_name, self.db)

    def _varchar_columns(self, headers):
        '''
        INPUT:
            headers -> list; list of names of columns for new table
        OUTPUT:
            string; the column section of a create table query

        Helper function to generate the column section of a create table query.
        '''
        var = '{0} varchar(100)'
        cols = [var.format(header) for header in headers]
        return ', '.join(cols)

    def insert_csv(self, table_name, csv_path, if_header=True):
        '''
        INPUT:
            table_name -> string; name of table to insert csv file
            csv_path -> string; file path of the csv file with data
            if_header -> boolean; true or false if csv includes headers

        Inserts csv file to table in the current database.  Table must already 
        exist in database.
        '''
        copy_query = "COPY {0} FROM '{1}' WITH DELIMITER ',' CSV {2};"
        if if_header:
            header = 'HEADER'
        else:
            header = ''
        self.cur.execute(copy_query.format(table_name, csv_path, header))
        self.conn.commit()
        print 'CSV inserted into {0}.'.format(table_name)

    def drop_table(self, table_name):
        '''
        INPUT:
            table_name -> string; name of table to drop

        Drops a table in the current database.  Will not attempt to drop if 
        table does not exist.
        '''
        drop_query = 'DROP TABLE IF EXISTS {0};'
        self.cur.execute(drop_query.format(table_name))
        self.conn.commit()
        print 'Table {0} dropped.'.format(table_name)

    def load_csvs_in_directory(self, directory):
        '''
        INPUT:
            directory -> string; directory of files to insert into psql

        Takes all csv files from the given directory, and creates tables and 
        inserts data into the current psql database.  Will not work if the data
         is not in csv or comma delimited format. 
        '''
        for f in os.listdir(directory):
            if f.endswith(file_type):
                file_path = '{0}/{1}'.format(directory, f)
                table_name = re.sub('-| ', '_', f.split('.')[0])
                headers = self._get_headers(file_path)
                self.drop_table(table_name)
                self.create_table(headers, table_name)
                self.insert_csv(table_name, file_path)

    def _get_headers(self, file_path):
        '''
        INPUT:
            file_path -> string; file_path of data file 
        OUTPUT:
            list; list of formatted headers
        Gets and formats the headers for query generation from the given file
        path.
        '''
        with open(file_path) as f:
            headers = f.readline().split(',')
            headers = [h.strip('\n').strip(' ').strip('"') for h in headers]
            headers = [re.sub(' |/', '_', h) for h in headers]
            return [re.sub('_+', '_', h) for h in headers]

    def end_connection(self):
        '''
        Closes the current psql connection.
        '''
        self.conn.close()
        print 'Connection Closed'